---
title: "RMDay3"
author: "Rakyan Satrya Adhikara"
date: "7/8/2019"
output: html_document
---

```{r setup, include=FALSE}
library(lmtest,warn.conflicts = F)
library(dplyr)
library(car,warn.conflicts = F)
crime <- read.csv("data_input/crime.csv") %>% select(-X)
names(crime) <- c("percent_m", "is_south", "mean_education", "police_exp60", "police_exp59", "labour_participation", "m_per1000f", "state_pop", "nonwhites_per1000", "unemploy_m24", "unemploy_m39", "gdp", "inequality", "prob_prison", "time_prison", "crime_rate")
knitr::opts_chunk$set(echo = TRUE)
```

### Stepwise

model_full -> predict inequality based on all predictor
model_none -> predict inequality without any predictor

```{r}
model_full <- lm(inequality~.,crime)
model_none <- lm(inequality~1,crime)
summary(model_none)
summary(model_full)
```

#### Step Function

```{r}
model_backward <- step(model_full, direction = "backward")
summary(model_backward)
```

```{r}
model_forward <- step(model_none, scope = list(lower = model_none, upper = model_full), direction = "forward")
summary(model_forward)
```

```{r}
model_both_none <- step(model_none, scope = list(lower = model_none, upper = model_full), direction = "both")
model_both_full <- step(model_full, direction = "both")
summary(model_backward)$adj.r.square
summary(model_forward)$adj.r.square
summary(model_both_none)$adj.r.square
summary(model_both_full)$adj.r.square

```

### Assumption
* #### Residual normally spreaded 'shapiro.test'

H0: Residual normally spreaded
H1: Residual **not** normally spreaded

Declining H0 Hypothesis if **P-Value < Alpha**

Residual can be accepted as 'normal' if p-value > 0,05

```{r}
hist(model_both_none$residuals, breaks = 100)
shapiro.test(model_both_none$residuals)
```


* #### Unpatterned Residual 'lmtest::bptes'

H0: Homostedasticity Model
H1: Heterostedasticity Model

Model can be accepted as Homostedasticity if p-value > alpha

```{r}
plot(crime$inequality, model_both_none$residuals, ylim = c(-25,25))
abline(h = 0, col = "red")
```


* #### Every x (predictors) are nor relateable to each other 'car::vif' -> multicolinearity

vif < 10 -> GOOD
vif > 10 -> BAD

```{r}
vif(model_both_none)
```


* #### Linearity 'cor.text'

H0: Correlaion is equal to 0
H1: Correlation is not equal to 0

```{r}
cor.test(crime$inequality, crime$gdp)
```


## Terms that are being used in 'Machine-Learning':
* X1, X2, X3, ... -> Predictors, Independent Variables
* Y -> Target, Dependent Variable
* Residual = Error -> 'Expectation - Reality'
* R-Squared -> on what percentage the predictor can describe the target
